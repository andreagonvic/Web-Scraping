{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Nombre': ['Iberdrola', 'Santander', 'Inditex', 'Amadeus', 'Repsol', 'BBVA', 'Telefónica', 'Cellnex Telecom', 'Ferrovial', 'PharmaMar', 'Siemens Gamesa', 'Aena', 'Naturgy Energy', 'Endesa', 'Red Eléctrica', 'CaixaBank', 'MásMóvil', 'MásMóvil', 'Enagás', 'ACS', 'IAG', 'Grifols', 'Banco Sabadell', 'Bankinter', 'Merlin Properties', 'Acciona', 'Solaria', 'Mapfre', 'Acerinox', 'Indra', 'ArcelorMittal', 'Colonial', 'Cie Automotive', 'ENCE', 'Meliá Hotels', 'Bankia', 'Viscofan', 'Nyesa Valores Corp', 'Almirall', 'Sacyr', 'Logista', 'Fluidra', 'Applus', 'Audax Renovables', 'Mediaset', 'Técnicas Reunidas', 'Airbus Group', 'Rovi', 'Vidrala', 'Grifols Pref'], 'Último valor': ['10,310', '1,644', '21,680', '40,155', '5,272', '2,366', '2,969', '53,70', '19,440', '110,300', '24,220', '113,90', '16,335', '22,810', '15,605', '1,570', '22,50', '22,50', '18,960', '20,220', '1,032', '23,845', '0,261', '3,158', '5,73', '90,100', '15,740', '1,280', '6,890', '5,370', '11,606', '6,020', '15,990', '1,875', '3,010', '1,062', '53.550', '0,0073', '9,010', '1,421', '14,18', '15,100', '6,75', '1,9740', '2,678', '6,660', '61,700', '31,000', '83,200', '14,820'], 'Máx. valor': ['10,557', '1,701', '22,250', '41,420', '5,396', '2,404', '3,003', '54,51', '19,805', '123,600', '24,880', '116,40', '17,200', '23,570', '15,953', '1,617', '22,52', '22,51', '19,265', '21,000', '1,054', '24,270', '0,268', '3,247', '5,85', '91,675', '16,140', '1,288', '7,180', '5,740', '11,790', '6,100', '16,830', '1,968', '3,074', '1,096', '54.500', '0,0096', '9,215', '1,459', '14,46', '15,460', '7,05', '2,1400', '2,762', '6,930', '62,990', '31,100', '84,000', '14,940'], 'Min. valor': ['10,235', '1,628', '21,515', '40,120', '5,150', '2,305', '2,907', '53,23', '19,137', '109,200', '23,905', '111,70', '16,137', '22,595', '15,537', '1,560', '22,50', '22,50', '18,750', '20,110', '1,004', '23,555', '0,257', '3,086', '5,65', '89,300', '15,640', '1,232', '6,810', '5,355', '11,334', '5,890', '15,820', '1,787', '2,942', '1,055', '53.425', '0,0071', '8,975', '1,401', '13,94', '14,500', '6,52', '1,9600', '2,666', '6,525', '60,200', '30,200', '81,400', '14,580'], 'Variación': ['-0,315', '-0,054', '-0,930', '-2,505', '-0,188', '-0,040', '-0,026', '+0,16', '-0,560', '+0,400', '-0,630', '-5,40', '-1,100', '-0,820', '-0,370', '-0,049', '0,00', '-0,02', '-0,405', '-0,780', '-0,035', '-0,630', '-0,011', '-0,105', '-0,22', '-2,200', '-0,240', '-0,010', '-0,408', '-0,300', '-0,216', '-0,150', '-0,550', '-0,124', '-0,110', '-0,029', '-0.950', '-0,0014', '-0,320', '-0,065', '-0,02', '+0,240', '-0,28', '-0,1160', '-0,118', '-0,345', '-2,690', '0,000', '-0,800', '-0,240'], '% Variación': ['-2,96%', '-3,17%', '-4,11%', '-5,87%', '-3,44%', '-1,66%', '-0,87%', '+0,30%', '-2,80%', '+0,36%', '-2,54%', '-4,53%', '-6,31%', '-3,47%', '-2,32%', '-2,99%', '0,00%', '-0,09%', '-2,09%', '-3,71%', '-3,23%', '-2,57%', '-4,08%', '-3,22%', '-3,62%', '-2,38%', '-1,50%', '-0,78%', '-5,59%', '-5,29%', '-1,83%', '-2,43%', '-3,33%', '-6,20%', '-3,53%', '-2,61%', '-1.74%', '-16,09%', '-3,43%', '-4,37%', '-0,14%', '+1,62%', '-3,98%', '-5,55%', '-4,22%', '-4,93%', '-4,18%', '0,00%', '-0,95%', '-1,59%'], 'Volumen': ['17,98M', '84,70M', '4,77M', '2,25M', '14,36M', '28,96M', '19,05M', '919,29K', '2,34M', '389,45K', '1,69M', '283,71K', '1,96M', '1,28M', '1,85M', '17,34M', '1,08M', '1,08M', '1,25M', '1,17M', '21,87M', '885,82K', '68,77M', '5,41M', '2,27M', '125,19K', '670,89K', '7,98M', '1,43M', '1,61M', '701,73K', '1,26M', '435,21K', '3,61M', '2,08M', '5,10M', '92.87K', '662,37M', '531,67K', '3,34M', '328,70K', '279,65K', '595,41K', '1,96M', '1,09M', '387,66K', '37,33K', '69,63K', '24,51K', '133,35K'], 'Hora': ['17:30:03', '17:34:57', '17:29:54', '17:30:03', '17:29:59', '17:29:42', '17:34:57', '17:34:55', '17:34:56', '17:35:24', '17:30:03', '17:34:55', '17:34:57', '17:34:56', '17:29:59', '17:34:57', '17:35:24', '17:30:04', '17:34:57', '17:34:57', '17:34:41', '17:29:59', '17:34:57', '17:34:57', '17:34:57', '17:34:57', '17:35:24', '17:34:57', '17:34:57', '17:34:57', '17:34:57', '17:34:56', '17:34:55', '17:34:57', '17:34:57', '17:34:56', '', '17:35:24', '17:29:23', '17:30:03', '17:35:24', '17:35:24', '17:35:24', '17:35:24', '17:34:55', '17:33:56', '17:35:24', '17:35:24', '17:35:24', '17:35:24']}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def most_active_stocks(url):\n",
    "     \n",
    "    #Para descargar el contenido de la pagina\n",
    "    import requests\n",
    "    r=requests.get(url)\n",
    "\n",
    "    #Creamos el árbol de objetos Python que representan al documento HTML (la sopa)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "    \n",
    "    #Tenemos que \"engañar\" a la pagina, para que crea que somos un navegador, por ello, incluimos headers, sino, obtendriamos el siguiente error:\n",
    "    #<title>403 You are banned from this site.  Please contact via a different client configuration if you believe that this is a mistake.</title>\n",
    "\n",
    "    header={'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2227.0 Safari/537.36'}\n",
    "    page=requests.get(url,headers=header)\n",
    "\n",
    "    # Creamos las listas y el diccionario para recoger el data set\n",
    "    list_name = []\n",
    "    list_last = []\n",
    "    list_high = []\n",
    "    list_vol = []\n",
    "    list_low = []\n",
    "    list_time = []\n",
    "    list_var = []\n",
    "    list_por_var = []\n",
    "    dict_data = {}\n",
    "    \n",
    "    # Comprobamos que la petición nos devuelve un Status Code = 200\n",
    "    status_code = page.status_code\n",
    "    if status_code == 200:\n",
    "        \n",
    "        soup=BeautifulSoup(page.content,'html.parser')\n",
    "        result = soup.find('td',attrs={'class':'left bold plusIconTd elp'})\n",
    "    \n",
    "        # Crearemos un bucle que vaya recogiendo los datos y los vaya metiendo a sus corresponeintes listas\n",
    "        for link in soup.find_all('td',attrs={'class':'left bold plusIconTd elp'}):\n",
    "            name= link.get_text()\n",
    "            list_name.append(name)\n",
    "            \n",
    "            line = link.find('span',{'class':'alertBellGrayPlus js-plus-icon genToolTip oneliner'})\n",
    "            id_valor = re.findall('\\D(\\d{3,7})\\D', str(line))\n",
    "            new_class_1 = \"align_right pid-\"+ id_valor[0] +\"-last\"\n",
    "            last=soup.find('td',attrs={'class':new_class_1}).getText()\n",
    "            list_last.append(last)\n",
    "\n",
    "            new_class_2 = \"pid-\"+ id_valor[0] +\"-time\"\n",
    "            time=soup.find('td',attrs={'class':new_class_2}).getText()\n",
    "            list_time.append(time)\n",
    "\n",
    "            new_class_3 = \"pid-\"+ id_valor[0] +\"-turnover\"\n",
    "            vol=soup.find('td',attrs={'class':new_class_3}).getText()\n",
    "            list_vol.append(vol)\n",
    "\n",
    "            new_class_4 = \"align_right pid-\"+ id_valor[0] +\"-high\"\n",
    "            high=soup.find('td',attrs={'class':new_class_4}).getText()\n",
    "            list_high.append(high)\n",
    "\n",
    "            new_class_5 = \"pid-\"+ id_valor[0] +\"-low\"\n",
    "            low=soup.find('td',attrs={'class':new_class_5}).getText()\n",
    "            list_low.append(low)\n",
    "\n",
    "            if soup.find('td',attrs={'class':\"bold redFont pid-\"+id_valor[0]+\"-pc\"}) != None:\n",
    "                var = soup.find('td',attrs={'class':\"bold redFont pid-\"+id_valor[0]+\"-pc\"}).getText()\n",
    "                por_var = soup.find('td',attrs={'class':\"bold redFont pid-\"+id_valor[0]+\"-pcp\"}).getText()\n",
    "\n",
    "            elif soup.find('td',attrs={'class':\"bold greenFont pid-\"+id_valor[0]+\"-pc\"}) != None:\n",
    "                var = soup.find('td',attrs={'class':\"bold greenFont pid-\"+id_valor[0]+\"-pc\"}).getText()\n",
    "                por_var = soup.find('td',attrs={'class':\"bold greenFont pid-\"+id_valor[0]+\"-pcp\"}).getText()\n",
    "\n",
    "            else:\n",
    "                var = soup.find('td',attrs={'class':\"bold blackFont pid-\"+id_valor[0]+\"-pc\"}).getText()\n",
    "                por_var = soup.find('td',attrs={'class':\"bold blackFont pid-\"+id_valor[0]+\"-pcp\"}).getText()\n",
    "\n",
    "            list_var.append(var)\n",
    "            list_por_var.append(por_var)\n",
    "            \n",
    "        # Creamos las entreadas del diccionario y lo convertimos en un dataframe\n",
    "        dict_data['Nombre'] = list_name\n",
    "        dict_data['Último valor'] = list_last\n",
    "        dict_data['Máx. valor'] = list_high\n",
    "        dict_data['Min. valor'] = list_low\n",
    "        dict_data['Variación'] = list_var\n",
    "        dict_data['% Variación'] = list_por_var\n",
    "        dict_data['Volumen'] = list_vol\n",
    "        dict_data['Hora'] = list_time\n",
    "\n",
    "        df = pd.DataFrame(dict_data, columns = ['Nombre', 'Último valor', 'Máx. valor', 'Min. valor', 'Variación', '% Variación', 'Volumen', 'Hora'])\n",
    "\n",
    "        # Descargamos un archivo .csv \n",
    "        final_datafile = df.to_csv('WebScraping_SP_stocks.csv', sep=';')\n",
    "    else:\n",
    "        print(\"Status Code %d\" % status_code)\n",
    "    \n",
    "    \n",
    "    return\n",
    "    \n",
    "\n",
    "# Ejecutamos la función creada\n",
    "most_active_stocks(\"https://es.investing.com/equities/most-active-stocks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
